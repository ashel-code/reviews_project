{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "import keras.layers as layers\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "from db_actions import DatabaseActions as db\n",
    "import tokenizing\n",
    "from frequency_analysis import get_prob\n",
    "from structure.train_data import StoredData\n",
    "\n",
    "\n",
    "print('TensorFlow version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = db.get_parsed()\n",
    "\n",
    "storedData = StoredData(data, \n",
    "                        do_smote=True,\n",
    "                        smote_ratio=0.6,\n",
    "                        class_ratio=4.5,\n",
    "                        test_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(storedData.x_train.shape)\n",
    "print(type(storedData.x_train[0]), len(storedData.x_train[0]))\n",
    "print(type(storedData.x_train[0][0]))\n",
    "print(type(storedData.x_train), len(storedData.x_train))\n",
    "print(type(storedData.y_train), len(storedData.y_train))\n",
    "print(type(storedData.y_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a simple CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation\n",
    "    model.add(layers.Conv2D(256, (9, 9), activation='tanh', input_shape=input_shape))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(256, activation='tanh'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "\n",
    "    # Max pooling layer with 2x2 pool size\n",
    "    model.add(layers.MaxPooling2D((3, 3)))\n",
    "    \n",
    "    # Convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n",
    "    model.add(layers.Conv2D(512, (4, 4), activation='tanh'))\n",
    "\n",
    "    model.add(layers.Dense(256, activation='tanh'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    \n",
    "    # Max pooling layer with 2x2 pool size\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten the output from the previous layer\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    # Fully connected layer with 64 units and ReLU activation\n",
    "    model.add(layers.Dense(256, activation='tanh'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    \n",
    "    # Output layer with 1 unit and sigmoid activation for binary classification\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "# Create an instance of the model\n",
    "input_shape = (24, 32, 1) # Example shape, adjust based on your data\n",
    "model = create_cnn_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9),\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=[tf.keras.metrics.AUC(curve='ROC')])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[ tf.keras.metrics.AUC(curve='ROC'),\n",
    "                        keras.metrics.Precision(name='precision'),\n",
    "                        keras.metrics.Recall(name='recall')])                                      \n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.fit(storedData.x_train, storedData.y_train, epochs=30, verbose=1)\n",
    "\n",
    "res = model.predict(storedData.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def find_optimal_threshold(pred_probs, y_true):\n",
    "    low = 0.0  # Lowest possible threshold value\n",
    "    high = 1.0  # Highest possible threshold value\n",
    "    epsilon = 1e-6  # Small value for threshold precision\n",
    "    best_threshold = 0.2  # Initial threshold value\n",
    "    best_accuracy = 0.0  # Initial best accuracy\n",
    "\n",
    "    while low <= high:\n",
    "        threshold = (low + high) / 2.0  # Calculate the mid-point threshold\n",
    "\n",
    "        # Convert predicted probabilities into binary predictions using the threshold\n",
    "        predictions = [1 if prob >= threshold else 0 for prob in pred_probs]\n",
    "\n",
    "        # Calculate accuracy using the binary predictions and true labels\n",
    "        accuracy = accuracy_score(y_true, predictions)\n",
    "\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_threshold = threshold\n",
    "\n",
    "        if accuracy + epsilon >= best_accuracy:\n",
    "            low = threshold + epsilon\n",
    "        else:\n",
    "            high = threshold - epsilon\n",
    "\n",
    "    return best_threshold, best_accuracy\n",
    "\n",
    "find_optimal_threshold(res, storedData.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(95, 105):\n",
    "#     print(i, y_train[i], texts[i], sep= '\\t', end='\\t')\n",
    "#     print()\n",
    "\n",
    "print(storedData.y_test)\n",
    "\n",
    "ct = 0\n",
    "for i in range(len(storedData.y_test)):\n",
    "    if storedData.y_test[i] == 0:\n",
    "        ct += 1\n",
    "ct2 = 0\n",
    "for i in range(len(res)):\n",
    "    if res[i] >= 0.5:\n",
    "        ct2 += 1\n",
    "\n",
    "print(ct)\n",
    "print(ct2)\n",
    "# dif = np.median(res)\n",
    "dif, b_a = find_optimal_threshold(res, storedData.y_test)\n",
    "\n",
    "print(dif, b_a)\n",
    "dif = 0.5\n",
    "\n",
    "c = 0\n",
    "for i in range(len(storedData.x_test)):\n",
    "    if (res[i] > dif) == storedData.y_test[i]:\n",
    "        print(\"YES\", res[i] > dif, storedData.y_test[i], res[i])\n",
    "        c += 1\n",
    "    else:\n",
    "        print(\"NO\", res[i] > dif, storedData.y_test[i], res[i])\n",
    "print(c, len(storedData.x_test))\n",
    "print(c / len(storedData.x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(storedData.x_test)):\n",
    "    print(\"–¥–∞\" if (res[i] > dif) == storedData.y_test[i] else \"–Ω–µ—Ç\", res[i], res[i] > dif, storedData.y_test[i], storedData.texts_test[i], sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_review(text):\n",
    "\n",
    "    vector = tokenizing.tokenize_one(text) \n",
    "    print(vector.shape)\n",
    "    vector = vector.reshape((24, 32))\n",
    "    print('~' * 80)\n",
    "    # print(vector)\n",
    "    return(model.predict(np.array([vector,])))\n",
    "\n",
    "txt1 = \"–ù–µ–≤–µ—Ä–æ—è—Ç–Ω–æ —É—é—Ç–Ω–æ–µ –∏ –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω–æ–µ –º–µ—Å—Ç–æ. –ó–¥–µ—Å—å –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ –≤—Å—ë: –º–µ–Ω—é, –≤–∏–Ω–Ω–∞—è –∫–∞—Ä—Ç–∞, —Å–µ—Ä–≤–∏—Å. –í –∑–∞–≤–µ–¥–µ–Ω–∏–∏ –¥–≤–∞ —ç—Ç–∞–∂–∞ - –Ω–∞ –ø–µ—Ä–≤–æ–º –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞ –±–∞—Ä–∞, –Ω–∞ –≤—Ç–æ—Ä–æ–º - —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞, –º—è–≥–∫–∏–π —É—é—Ç–Ω—ã–π —Å–≤–µ—Ç, –ø—Ä–∏—è—Ç–Ω–∞—è –ø—É–±–ª–∏–∫–∞, –Ω–µ–Ω–∞–≤—è–∑—á–∏–≤–∞—è –º—É–∑—ã–∫–∞ –∏ –∏–Ω—Ç–µ—Ä—å–µ—Ä. –≠—Ç–æ –º–µ—Å—Ç–æ —Å –∏—Å—Ç–æ—Ä–∏–µ–π - –∑–¥–∞–Ω–∏–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–æ –≤ 1908 –≥–æ–¥—É (–æ—Ç—Å—é–¥–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ), –∞ –∑–∞–≤–µ–¥–µ–Ω–∏–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –Ω–∞—Å—Ç–æ—è—â–µ–π –∞—Ä–∫–µ, –ø–æ–¥ —Å–≤–æ–¥–∞–º–∏ –∫–æ—Ç–æ—Ä–æ–π —Å—Ç–æ—è—Ç —Å—Ç–æ–ª–∏–∫–∏. –ó–¥–µ—Å—å –ø—Ä–∏—è—Ç–Ω–æ –ø–æ—É–∂–∏–Ω–∞—Ç—å –∏ –ø—Ä–∏–π—Ç–∏ –Ω–∞ –∑–∞–≤—Ç—Ä–∞–∫, –∑–∞–±–µ–∂–∞—Ç—å –Ω–∞ –æ–±–µ–¥. –û–±—Å—Ç–∞–Ω–æ–≤–∫–∞ –∫–∞–∫ –±—ã –æ–±–Ω–∏–º–∞–µ—Ç —Ç–µ–±—è –∏ –ø–æ–≥—Ä—É–∂–∞–µ—Ç –≤ —Å—Ç–∏–ª—å –∏ —É—é—Ç. –ó–¥–µ—Å—å –ø–æ–ª—É—á–∞—é—Ç—Å—è –æ—á–µ–Ω—å —Å—Ç–∏–ª—å–Ω—ã–µ —Ñ–æ—Ç–æ üòâ –ï–¥–∞ –≤–∫—É—Å–Ω–∞—è, –ø—Ä–∏–Ω–æ—Å—è—Ç –±—ã—Å—Ç—Ä–æ. –ú–Ω–µ –≤—Å–µ–≥–¥–∞ —Ö–æ—á–µ—Ç—Å—è —Å—é–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞ –∏ —Å–Ω–æ–≤–∞\"\n",
    "txt2 = \"–ù–µ–¥–∞–≤–Ω–æ –ø–æ—Å–µ—Ç–∏–ª–∞ —Å –º–æ–∏–º–∏ –≥–æ—Å—Ç—è–º–∏ —Ä–µ—Å—Ç–æ—Ä–∞–Ω ¬´–°—É–Ω–µ–ª–∏¬ª. –ü–æ—Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–ª–∏ –¥—Ä—É–∑—å—è –∫–∞–∫ –º–∞–ª–µ–Ω—å–∫–∏–π —É–≥–æ–ª–æ–∫ –ì—Ä—É–∑–∏–∏ —Å–æ –≤–∫—É—Å–Ω–æ–π –∫—É—Ö–Ω–µ–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–º –ø–µ—Ä—Å–æ–Ω–∞–ª–æ–º. –ë—ã–ª–æ –≤—Å—ë –Ω–∞–º–Ω–æ–≥–æ –ª—É—á—à–µ, —á–µ–º –æ–∂–∏–¥–∞–ª–∏. –ö—Ä–∞—Å–∏–≤—ã–π –∏–Ω—Ç–µ—Ä—å–µ—Ä, —Ç–∏—Ö–∞—è —Ñ–æ–Ω–æ–≤–∞—è –º—É–∑—ã–∫–∞, –ø—Ä–∏—è—Ç–Ω–∞—è –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞—Å—Ç—Ä–æ–∏–ª–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –Ω–∞—Å—Ç—Ä–æ–π —Å –ø–µ—Ä–≤–æ–π –º–∏–Ω—É—Ç—ã. –ê –≤–∫—É—Å–Ω–∞—è –µ–¥–∞, –æ—Ç–ª–∏—á–Ω—ã–µ –¥–µ—Å–µ—Ä—Ç—ã —Å –∫–æ—Ñ–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∏ –º–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏–π—Ç–∏ —Å—é–¥–∞ –µ—â—ë –Ω–µ —Ä–∞–∑. –†–µ–∫–æ–º–µ–Ω–¥—É—é –≤—Å–µ–º, –∫—Ç–æ –ª—é–±–∏—Ç –≥—Ä—É–∑–∏–Ω—Å–∫—É—é –∫—É—Ö–Ω—é, –Ω–µ–Ω–∞–≤—è–∑—á–∏–≤—ã–π –ø–µ—Ä—Å–æ–Ω–∞–ª –∏ –ø—Ä–∏—è—Ç–Ω—ã–µ —Ü–µ–Ω—ã!\"\n",
    "txt3 = \"–Ø –ø–æ—Å—Ç–∞—è–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –ø–æ—Å—Ç–∞—è–Ω–Ω–æ –ø—Ä–∏–µ–∂–∞—é –∫—É—à–∞—é –ø–æ—Å—Ç–∞—è–Ω–Ω–æ –Ω–µ –æ–±—Ä–∞—à–∞–µ—Ç—å –≤–Ω–∏–º–∞–Ω–∏—è –∫ –∫–ª–∏–µ–Ω—Ç—É –∂–¥–µ—à—å –∂–¥–µ—à—å –∂–¥–µ—à—å —Å–∞–º–∏ —Ö–æ–¥—è—Ç —Ç—Ä–∏ —á–µ—Ç—ã—Ä–µ —á–µ–ª–æ–≤–µ–∫ –Ω–µ –æ–¥–∏–Ω –∏–∑ –Ω–∏—Ö –Ω–µ —Å–º–æ—Ç—Ä–∏—Ç —á—Ç–æ –∫–ª–∏–µ–Ω—Ç –ø—Ä–∏—à–µ–ª —Å–µ–ª—å —É–∂–µ –∂–¥–µ—Ç –æ–±—è—Å–Ω–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –æ—Ñ–∏—Ü–∏–∞–Ω—Ç–∞–º —á—Ç–æ–±—ã –æ–Ω–∏ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏–µ—Ö–∞–ª –ø–æ –∫—É—à–∞—Ç—å –∫–∞–∑–∞–Ω—å –∫–µ–±–∞–± –±–∞—Ä–∞–Ω–∏–Ω–∞ –æ–Ω–∏ –º–Ω–µ –ø—Ä–∏–≤–∏–∑–ª–∏ –æ–¥–Ω–∏ –∂—ã—Ä —è –ø—Ä–æ—Å–∏–ª –º–æ–∂–Ω–æ –º—è—Å–æ –∂—ã—Ä –Ω–µ –º–æ–≥—É –∫—É—à–∞—Ç—å –æ–Ω–∏ –ø—Ä–∏–≤–∏–∑–ª–∏ –º—è—Å–æ —Ö–æ–ª–æ–¥–Ω—ã–π –¥–∞–∂–µ –Ω–µ –ø–æ–≥—Ä–µ–ª –æ–±—å—è—Å–Ω–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ —Å–ø–∞—Å–∏–±–æ\"\n",
    "txt4 = \"–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ, —Ä–æ–º–∞–Ω—Ç–∏—á–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ! –ü–æ –≤—ã—Ö–æ–¥–Ω—ã–º, –Ω–∞—á–∏–Ω–∞—è —Å –ø—è—Ç–Ω–∏—Ü–µ, –ø—Ä–æ—Ö–æ–¥—è—Ç —Ö–æ—Ä–æ—à–∏–µ —Ç—É—Å–æ–≤–æ—á–∫–∏ —Å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–π –º—É–∑—ã–∫–æ–π. –ï–¥–∞ –∏ —Ü–µ–Ω–∞, –∫–∞–∫ –≤–µ–∑–¥–µ.\"\n",
    "txt5 = \"–ó–∞—à–ª–∏ —Å –¥—Ä—É–≥–æ–º –≤ –õ–∞–º–±–∏–∫ 28 –º–∞—Ä—Ç–∞, –Ω–∞ –≤—Ö–æ–¥–µ –≤—Å—Ç—Ä–µ—Ç–∏–ª–∞ –º–∏–ª–∞—è –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–∞—è –¥–µ–≤—É—à–∫–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä, –ø—Ä–µ–¥–ª–æ–∂–∏–ª–∞ —É—é—Ç–Ω—ã–π —Å—Ç–æ–ª–∏–∫ —É –æ–∫–Ω–∞. –û—Ñ–∏—Ü–∏–∞–Ω—Ç–∫–∞ –ø–æ–¥–æ—à–ª–∞ –±—ã—Å—Ç—Ä–æ, –ø–æ–º–æ–≥–ª–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å—Å—è —Å –≤—ã–±–æ—Ä–æ–º –∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ –∑–∞–∫–∞–∑ –Ω–∞–º –ø—Ä–∏–Ω–µ—Å–ª–∞. –û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ –æ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω–∞ - –Ω–µ–±–æ–ª—å—à–æ–µ —É—é—Ç–Ω–æ–µ –∑–∞–≤–µ–¥–µ–Ω–∏–µ, –∫–∞–∫ —Ä–∞–∑ –≤ —Å—Ç–∏–ª–µ –∑–∞–≤–µ–¥–µ–Ω–∏–π —Ç–æ–≥–æ —Ä–∞–π–æ–Ω–∞ (–ü–∞—Ç—Ä–∏–∞—Ä—à–∏–µ –ø—Ä—É–¥—ã), –∏ —Ç–∞–∫–∞—è –∫–∞–º–µ—Ä–Ω–æ—Å—Ç—å –¥–µ–ª–∞–µ—Ç —Ä–µ—Å—Ç–æ—Ä–∞–Ω –æ—á–µ–Ω—å —Å–∏–º–ø–∞—Ç–∏—á–Ω—ã–º –∏ –Ω–µ –ø–∞—Ñ–æ—Å–Ω—ã–º. –ü–∏–≤–æ –≤–∫—É—Å–Ω–æ–µ, —Å–µ—Ä–≤–∏—Å –Ω–∞ —É—Ä–æ–≤–Ω–µ. –í –æ–±—â–µ–º, –Ω–∞–º –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å. –°–ø–∞—Å–∏–±–æ –õ–∞–º–±–∏–∫—É –∏ –º–µ–Ω–µ–¥–∂–µ—Ä—É –õ–∞—Ä–∏—Å–µ, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤–µ—Ä–Ω—ë–º—Å—è)\"\n",
    "\n",
    "r1 = check_review(txt1)\n",
    "r2 = check_review(txt2)\n",
    "r3 = check_review(txt3)\n",
    "r4 = check_review(txt4)\n",
    "r5 = check_review(txt5)\n",
    "print(dif)\n",
    "print(\"~\" * 80)\n",
    "print(dif <= r1, r1)\n",
    "print(dif <= r2, r2)\n",
    "print(dif <= r3, r3)\n",
    "print(dif <= r4, r4)\n",
    "print(dif <= r5, r5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = check_review(\"–∏–¥–µ–∞–ª—å—à–µ–π—à–∞—è –∫–æ—Ä—á–º–∞ -- –æ–Ω–∞ –æ—á–µ–Ω—å —Å–∏–ª—å–Ω–æ –ø–æ–Ω—Ä–∞–≤–∏—Ç—Å—è. –¥–ª—è –∏—Å—Ç–∏–Ω–Ω—ã—Ö –≥—É—Ä–º–∞–Ω–æ–≤\")\n",
    "\n",
    "print(dif <= tmp, tmp, dif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frequency_analysis import texts\n",
    "# print(texts)\n",
    "\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    data.append(get_prob(texts[i]))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d1 = np.array(data[0:100])\n",
    "d1.sort()\n",
    "# d1 = d1[0:90]\n",
    "\n",
    "d2 = np.array(data[100:200])\n",
    "d2.sort()\n",
    "\n",
    "# d2 = d2[0:90]\n",
    "# Create a line plot\n",
    "plt.plot(d1)\n",
    "plt.plot(d2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Array Data Visualization')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "print(\"fake\", np.median(d1), np.average(d1))\n",
    "print(\"normal\", np.median(d2), np.average(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr('raise') \n",
    "d3 = []\n",
    "s = 0.0\n",
    "for i in range(1, len(d1)):\n",
    "    print(d1[i], d2[i])\n",
    "    s = s + d1[i] / d2[i]\n",
    "    d3.append(s)\n",
    "print(d3)\n",
    "plt.plot(d3)\n",
    "# Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Array Data Visualization')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.seterr('raise') \n",
    "d4 = []\n",
    "d1[:] = d1[::-1]\n",
    "d2[:] = d2[::-1]\n",
    "s = 0.0\n",
    "for i in range(1, len(d1)):\n",
    "    s = s + d1[i]\n",
    "    d4.append(s)\n",
    "\n",
    "plt.plot(d4)\n",
    "\n",
    "d5 = []\n",
    "s = 0.0\n",
    "for i in range(1, len(d1)):\n",
    "\n",
    "    s = s + d2[i]\n",
    "    d5.append(s)\n",
    "\n",
    "plt.plot(d5)\n",
    "# Add labels and title\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Array Data Visualization')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "lr_probs = model.predict(storedData.x_test)\n",
    "# keep probabilities for the positive outcome only\n",
    "# lr_probs = lr_probs[:, 1]\n",
    "\n",
    "ns_probs = [0 for _ in range(len(storedData.y_test))]\n",
    "\n",
    "# calculate scores\n",
    "ns_auc = roc_auc_score(storedData.y_test, ns_probs)\n",
    "lr_auc = roc_auc_score(storedData.y_test, lr_probs)\n",
    "# summarize scores\n",
    "print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "# calculate roc curves\n",
    "\n",
    "ns_fpr, ns_tpr, _ = roc_curve(storedData.y_test, ns_probs)\n",
    "lr_fpr, lr_tpr, _ = roc_curve(storedData.y_test, lr_probs)\n",
    "# plot the roc curve for the model\n",
    "pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "# axis labels\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model.summary()\n",
    "model.save('model-06062023.h5')\n",
    "print('Saved model to disk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
